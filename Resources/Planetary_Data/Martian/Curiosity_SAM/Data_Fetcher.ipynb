{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "from bs4 import BeautifulSoup as BS\n",
    "import re # regex\n",
    "import os # for making directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<requests.adapters.HTTPAdapter at 0x7f269981bb80>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = req.Session()\n",
    "retry = req.packages.urllib3.util.retry.Retry(total = 5, backoff_factor = 0.1, status_forcelist = [500, 502, 503, 504])\n",
    "req.adapters.HTTPAdapter(max_retries = retry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://pds-geosciences.wustl.edu/msl/msl-m-sam-2-rdr-l0-v1/mslsam_1xxx/data/\"\n",
    "response = session.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if response.status_code == 200:\n",
    "    soup = BS(response.content, 'html.parser')\n",
    "\n",
    "    links = soup.find_all('a')\n",
    "    eid_regex = re.compile(r'eid\\d{5}')\n",
    "\n",
    "    eid_links = []\n",
    "\n",
    "    for link in links:\n",
    "        href = link.get('href')\n",
    "\n",
    "        if href and re.search(eid_regex, href):\n",
    "            eid_links.append(href)\n",
    "else:\n",
    "    print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_2_links = []\n",
    "\n",
    "for eid_link in eid_links:\n",
    "    eid_url = \"https://pds-geosciences.wustl.edu\" + eid_link\n",
    "    eid_response = session.get(eid_url)\n",
    "\n",
    "    if eid_response.status_code == 200:\n",
    "        eid_soup = BS(eid_response.content, 'html.parser')\n",
    "\n",
    "        links = eid_soup.find_all('a')\n",
    "        level_2_regex = re.compile(r'/level2')\n",
    "        level_2 = False\n",
    "        \n",
    "        for link in links:\n",
    "            href = link.get('href')\n",
    "            \n",
    "            if href and re.search(level_2_regex, href):\n",
    "                level_2_links.append(href)\n",
    "                level_2 = True\n",
    "\n",
    "        if not level_2:\n",
    "            level_2_links.append(\"NO_LEVEL_2_DATA\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_links = []\n",
    "\n",
    "for level_2_link  in level_2_links:\n",
    "    if level_2_link == \"NO_LEVEL_2_DATA\":\n",
    "        continue\n",
    "    else:\n",
    "        level_2_url = \"https://pds-geosciences.wustl.edu\" + level_2_link\n",
    "        level_2_response = session.get(level_2_url)\n",
    "\n",
    "    if level_2_response.status_code == 200:\n",
    "        level_2_soup = BS(level_2_response.content, 'html.parser')\n",
    "\n",
    "        links = level_2_soup.find_all('a')\n",
    "        csv_regex = re.compile(r'qms_atmcomp_\\d{1}.csv$')\n",
    "        csv = False\n",
    "\n",
    "        for link in links:\n",
    "            href = link.get('href')\n",
    "\n",
    "            if href and re.search(csv_regex, href):\n",
    "                csv_links.append(href)\n",
    "                csv = True\n",
    "\n",
    "        if not csv:\n",
    "            csv_links.append(\"NO_ATMCOMP_CSV_DATA\")\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n",
    "        \n",
    "csv_links_full = []\n",
    "\n",
    "for csv_link in csv_links:\n",
    "    if csv_link == \"NO_ATMCOMP_CSV_DATA\":\n",
    "        continue\n",
    "    else:\n",
    "        csv_links_full.append(\"https://pds-geosciences.wustl.edu\" + csv_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv_link_full in csv_links_full:\n",
    "    eid_name = re.compile(r'eid\\d{5}')\n",
    "    dir_name = re.findall(eid_name, csv_link_full)[0] # re.findall() returns an array\n",
    "    os.mkdir(dir_name)\n",
    "\n",
    "    csv_response = session.get(csv_link_full)\n",
    "    file_content = csv_response.content\n",
    "    file_name_regex = re.compile(r'sm\\d{5}.*$')\n",
    "    file_name = re.findall(file_name_regex, csv_link_full)[0]\n",
    "\n",
    "    with open(r'./' + dir_name + r'/' + file_name, 'wb') as file:\n",
    "        file.write(file_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
